{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f7d0236ae9e493c9e48f4ec6eb3ad41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_934170f7fcc7492fa4a0e45e82d94162",
              "IPY_MODEL_67a8c8a3ccac4ee497764aee9886f72b",
              "IPY_MODEL_5e9b681f1e254d83a71a8114c53abf24"
            ],
            "layout": "IPY_MODEL_5ff85d691c9644d3840a5c9e9b5a4c03"
          }
        },
        "934170f7fcc7492fa4a0e45e82d94162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160d40b4d30e40af997b8b2ce6f8f5db",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2001b96354294d6483f75f4ae5a7b349",
            "value": "Best‚Äátrial:‚Äá31.‚ÄáBest‚Äávalue:‚Äá0.483363:‚Äá100%"
          }
        },
        "67a8c8a3ccac4ee497764aee9886f72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ad70d5850346a99b0125cd743b0521",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_510efa2fb0204cdaaba9ded1a95bbc06",
            "value": 50
          }
        },
        "5e9b681f1e254d83a71a8114c53abf24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5c99205e7fd41ca94d3365c84bc1b79",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c646dd51d21949fbbad296dff9cb672c",
            "value": "‚Äá50/50‚Äá[01:15&lt;00:00,‚Äá‚Äá2.00s/it]"
          }
        },
        "5ff85d691c9644d3840a5c9e9b5a4c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160d40b4d30e40af997b8b2ce6f8f5db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2001b96354294d6483f75f4ae5a7b349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2ad70d5850346a99b0125cd743b0521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510efa2fb0204cdaaba9ded1a95bbc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5c99205e7fd41ca94d3365c84bc1b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c646dd51d21949fbbad296dff9cb672c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alVxWukpskLD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_df=pd.read_csv('cleaned_emotions.csv').iloc[:,3:]\n",
        "\n",
        "clean_test=pd.read_csv('cleaned.csv')\n",
        "final_df.shape,clean_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PsE9S-ft1Es",
        "outputId": "8dd2202d-9777-413f-e4df-085b78c76b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4991, 10), (1707, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNGD0XrDuI3j",
        "outputId": "c1b58336-653b-4eab-d95b-781118bcaaf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üöÄ Advanced Hyperparameter Tuning with Optuna & W&B\n",
        "Multi-Label Emotion Classification Pipeline\n",
        "Models: RandomForest, LinearSVC, CatBoost\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "import optuna\n",
        "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any\n",
        "import json\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import (\n",
        "    f1_score, accuracy_score, hamming_loss, jaccard_score,\n",
        "    classification_report, roc_auc_score\n",
        ")\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# üé® Configuration & Setup\n",
        "# =========================\n",
        "OUTPUT_DIR = Path(\"outputs/optuna_tuning\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EXPERIMENT_CONFIG = {\n",
        "    \"test_size\": 0.2,\n",
        "    \"random_state\": 42,\n",
        "    \"n_trials\": 50,  # Number of Optuna trials per model\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "}\n",
        "\n",
        "# Vectorizer configuration (using best from previous experiments)\n",
        "VECTORIZER_CONFIG = {\n",
        "    'max_features': 5000,\n",
        "    'ngram_range': (1, 3)  # Adjust based on your best result\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# 1Ô∏è‚É£ Data Preparation\n",
        "# =========================\n",
        "print(\"=\" * 80)\n",
        "print(\"üöÄ HYPERPARAMETER TUNING WITH OPTUNA & W&B\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Prepare data\n",
        "X = final_df['final_text'].fillna('')\n",
        "y = final_df[['anger', 'fear', 'joy', 'sadness', 'surprise']]\n",
        "emotions = y.columns.tolist()\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=EXPERIMENT_CONFIG['test_size'],\n",
        "    random_state=EXPERIMENT_CONFIG['random_state']\n",
        ")\n",
        "\n",
        "# Vectorize\n",
        "print(\"\\nüìê Vectorizing text data...\")\n",
        "vectorizer = CountVectorizer(\n",
        "    max_features=VECTORIZER_CONFIG['max_features'],\n",
        "    ngram_range=VECTORIZER_CONFIG['ngram_range']\n",
        ")\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec = vectorizer.transform(X_val)\n",
        "\n",
        "print(f\"‚úÖ Training samples: {X_train_vec.shape[0]}\")\n",
        "print(f\"‚úÖ Validation samples: {X_val_vec.shape[0]}\")\n",
        "print(f\"‚úÖ Features: {X_train_vec.shape[1]}\")\n",
        "\n",
        "# =========================\n",
        "# 2Ô∏è‚É£ Optuna Objective Functions\n",
        "# =========================\n",
        "\n",
        "def evaluate_model(model, X_train, X_val, y_train, y_val):\n",
        "    \"\"\"Evaluate multi-label model and return F1-macro score\"\"\"\n",
        "    try:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "        f1_macro = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "        return f1_macro\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error in evaluation: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# def objective_random_forest(trial):\n",
        "#     \"\"\"Optuna objective for RandomForest\"\"\"\n",
        "#     params = {\n",
        "#         'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
        "#         'max_depth': trial.suggest_int('max_depth', 10, 50),\n",
        "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "#         'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "#         'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "#         'random_state': EXPERIMENT_CONFIG['random_state'],\n",
        "#         'n_jobs': -1\n",
        "#     }\n",
        "\n",
        "#     model = OneVsRestClassifier(RandomForestClassifier(**params), n_jobs=-1)\n",
        "#     score = evaluate_model(model, X_train_vec, X_val_vec, y_train, y_val)\n",
        "\n",
        "#     return score\n",
        "\n",
        "\n",
        "def objective_linear_svc(trial):\n",
        "    \"\"\"Optuna objective for LinearSVC\"\"\"\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 0.001, 100, log=True),\n",
        "        'loss': trial.suggest_categorical('loss', ['hinge', 'squared_hinge']),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'dual': False,  # Must be False when penalty='l1'\n",
        "        'max_iter': trial.suggest_int('max_iter', 1000, 10000, step=1000),\n",
        "        'random_state': EXPERIMENT_CONFIG['random_state']\n",
        "    }\n",
        "\n",
        "    # Handle dual parameter constraint\n",
        "    if params['penalty'] == 'l2' and params['loss'] == 'hinge':\n",
        "        params['dual'] = True\n",
        "\n",
        "    model = OneVsRestClassifier(LinearSVC(**params), n_jobs=-1)\n",
        "    score = evaluate_model(model, X_train_vec, X_val_vec, y_train, y_val)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "# def objective_catboost(trial):\n",
        "#     \"\"\"Optuna objective for CatBoost\"\"\"\n",
        "#     params = {\n",
        "#         'iterations': trial.suggest_int('iterations', 100, 1000, step=100),\n",
        "#         'depth': trial.suggest_int('depth', 4, 10),\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
        "#         'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "#         'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
        "#         'random_state': EXPERIMENT_CONFIG['random_state'],\n",
        "#         'verbose': 0,\n",
        "#         'thread_count': -1\n",
        "#     }\n",
        "\n",
        "    model = OneVsRestClassifier(CatBoostClassifier(**params), n_jobs=-1)\n",
        "    score = evaluate_model(model, X_train_vec, X_val_vec, y_train, y_val)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 3Ô∏è‚É£ Hyperparameter Tuning Function\n",
        "# =========================\n",
        "\n",
        "def tune_model(model_name, objective_func, n_trials=50):\n",
        "    \"\"\"\n",
        "    Tune hyperparameters using Optuna with W&B tracking\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üîß TUNING: {model_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Initialize W&B run for this model\n",
        "    run = wandb.init(\n",
        "        project=\"23f3003030-t32025\",\n",
        "        name=f\"optuna-{model_name}-{EXPERIMENT_CONFIG['timestamp']}\",\n",
        "        config={\n",
        "            \"model\": model_name,\n",
        "            \"n_trials\": n_trials,\n",
        "            \"vectorizer\": VECTORIZER_CONFIG,\n",
        "            **EXPERIMENT_CONFIG\n",
        "        },\n",
        "        tags=[\"optuna\", \"hyperparameter-tuning\", model_name.lower()]\n",
        "    )\n",
        "\n",
        "    # Create Optuna study with W&B callback\n",
        "    wandb_callback = WeightsAndBiasesCallback(\n",
        "        metric_name=\"f1_macro\",\n",
        "        wandb_kwargs={\"project\": \"23f3003030-t32025\"}\n",
        "    )\n",
        "\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\",\n",
        "        study_name=f\"{model_name}_tuning\"\n",
        "    )\n",
        "\n",
        "    # Optimize with progress tracking\n",
        "    print(f\"üîÑ Running {n_trials} trials...\")\n",
        "    study.optimize(\n",
        "        objective_func,\n",
        "        n_trials=n_trials,\n",
        "        callbacks=[wandb_callback],\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Get best results\n",
        "    best_params = study.best_params\n",
        "    best_score = study.best_value\n",
        "\n",
        "    print(f\"\\n‚úÖ Best F1-Macro Score: {best_score:.4f}\")\n",
        "    print(f\"üìä Best Parameters:\")\n",
        "    for param, value in best_params.items():\n",
        "        print(f\"   ‚Ä¢ {param}: {value}\")\n",
        "\n",
        "    # Log best parameters to W&B\n",
        "    wandb.log({\n",
        "        \"best_f1_macro\": best_score,\n",
        "        \"best_params\": best_params,\n",
        "        \"n_trials_completed\": len(study.trials)\n",
        "    })\n",
        "\n",
        "    # Create optimization history plot\n",
        "    fig = optuna.visualization.plot_optimization_history(study)\n",
        "    wandb.log({\"optimization_history\": wandb.Plotly(fig)})\n",
        "\n",
        "    # Create parameter importance plot\n",
        "    try:\n",
        "        fig = optuna.visualization.plot_param_importances(study)\n",
        "        wandb.log({\"param_importance\": wandb.Plotly(fig)})\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Could not generate parameter importance plot\")\n",
        "\n",
        "    # Save study results\n",
        "    study_results = []\n",
        "    for trial in study.trials:\n",
        "        study_results.append({\n",
        "            'trial_number': trial.number,\n",
        "            'value': trial.value,\n",
        "            'params': trial.params,\n",
        "            'state': trial.state.name\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(study_results)\n",
        "    results_path = OUTPUT_DIR / f\"{model_name}_optuna_results.csv\"\n",
        "    results_df.to_csv(results_path, index=False)\n",
        "    wandb.save(str(results_path))\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    return best_params, best_score, study\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 4Ô∏è‚É£ Train Best Models\n",
        "# =========================\n",
        "\n",
        "def train_and_evaluate_best_model(model_name, best_params):\n",
        "    \"\"\"Train final model with best parameters and comprehensive evaluation\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üéØ FINAL TRAINING: {model_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Initialize W&B run for final training\n",
        "    run = wandb.init(\n",
        "        project=\"23f3003030-t32025\",\n",
        "        name=f\"final-{model_name}-{EXPERIMENT_CONFIG['timestamp']}\",\n",
        "        config={\n",
        "            \"model\": model_name,\n",
        "            \"best_params\": best_params,\n",
        "            \"stage\": \"final_training\"\n",
        "        },\n",
        "        tags=[\"final-model\", model_name.lower()],\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "    # Create model with best parameters\n",
        "    if model_name == \"RandomForest\":\n",
        "        base_model = RandomForestClassifier(**best_params)\n",
        "    elif model_name == \"LinearSVC\":\n",
        "        base_model = LinearSVC(**best_params)\n",
        "    elif model_name == \"CatBoost\":\n",
        "        base_model = CatBoostClassifier(**best_params)\n",
        "\n",
        "    model = OneVsRestClassifier(base_model, n_jobs=-1)\n",
        "\n",
        "    # Train on full training set\n",
        "    print(\"üîÑ Training final model...\")\n",
        "    model.fit(X_train_vec, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_val_vec)\n",
        "\n",
        "    # Get probabilities for ROC-AUC\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_pred_proba = model.predict_proba(X_val_vec)\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        y_pred_proba = model.decision_function(X_val_vec)\n",
        "        scaler = MinMaxScaler()\n",
        "        y_pred_proba = scaler.fit_transform(y_pred_proba)\n",
        "    else:\n",
        "        y_pred_proba = y_pred\n",
        "\n",
        "    # Comprehensive metrics\n",
        "    metrics = {\n",
        "        'f1_macro': f1_score(y_val, y_pred, average='macro', zero_division=0),\n",
        "        'f1_micro': f1_score(y_val, y_pred, average='micro', zero_division=0),\n",
        "        'f1_weighted': f1_score(y_val, y_pred, average='weighted', zero_division=0),\n",
        "        'hamming_loss': hamming_loss(y_val, y_pred),\n",
        "        'jaccard_score': jaccard_score(y_val, y_pred, average='samples', zero_division=0),\n",
        "        'subset_accuracy': accuracy_score(y_val, y_pred)\n",
        "    }\n",
        "\n",
        "    # Per-emotion metrics\n",
        "    for i, emotion in enumerate(emotions):\n",
        "        metrics[f'{emotion}_f1'] = f1_score(\n",
        "            y_val.iloc[:, i], y_pred[:, i], zero_division=0\n",
        "        )\n",
        "        try:\n",
        "            metrics[f'{emotion}_auc'] = roc_auc_score(\n",
        "                y_val.iloc[:, i], y_pred_proba[:, i]\n",
        "            )\n",
        "        except:\n",
        "            metrics[f'{emotion}_auc'] = 0.0\n",
        "\n",
        "    # Log all metrics\n",
        "    wandb.log(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"\\nüìä FINAL METRICS:\")\n",
        "    print(f\"   ‚Ä¢ F1-Macro: {metrics['f1_macro']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ F1-Micro: {metrics['f1_micro']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ F1-Weighted: {metrics['f1_weighted']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ Hamming Loss: {metrics['hamming_loss']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ Jaccard Score: {metrics['jaccard_score']:.4f}\")\n",
        "    print(f\"   ‚Ä¢ Subset Accuracy: {metrics['subset_accuracy']:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(\n",
        "        y_val, y_pred, target_names=emotions,\n",
        "        output_dict=True, zero_division=0\n",
        "    )\n",
        "\n",
        "    # Log classification report\n",
        "    for emotion in emotions:\n",
        "        if emotion in class_report:\n",
        "            wandb.log({\n",
        "                f\"{emotion}_precision\": class_report[emotion]['precision'],\n",
        "                f\"{emotion}_recall\": class_report[emotion]['recall'],\n",
        "                f\"{emotion}_f1\": class_report[emotion]['f1-score']\n",
        "            })\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    return model, metrics\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 5Ô∏è‚É£ Run Complete Pipeline\n",
        "# =========================\n",
        "\n",
        "# Define models to tune\n",
        "MODELS_TO_TUNE = {\n",
        "    # 'RandomForest': objective_random_forest,\n",
        "    'LinearSVC': objective_linear_svc\n",
        "    # 'CatBoost': objective_catboost\n",
        "}\n",
        "\n",
        "# Store all results\n",
        "all_results = {}\n",
        "best_models = {}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üöÄ STARTING HYPERPARAMETER TUNING PIPELINE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Tune each model\n",
        "for model_name, objective_func in MODELS_TO_TUNE.items():\n",
        "    # Hyperparameter tuning\n",
        "    best_params, best_score, study = tune_model(\n",
        "        model_name,\n",
        "        objective_func,\n",
        "        n_trials=EXPERIMENT_CONFIG['n_trials']\n",
        "    )\n",
        "\n",
        "    # Train final model with best parameters\n",
        "    final_model, final_metrics = train_and_evaluate_best_model(\n",
        "        model_name,\n",
        "        best_params\n",
        "    )\n",
        "\n",
        "    # Store results\n",
        "    all_results[model_name] = {\n",
        "        'best_params': best_params,\n",
        "        'tuning_score': best_score,\n",
        "        'final_metrics': final_metrics,\n",
        "        'study': study\n",
        "    }\n",
        "    best_models[model_name] = final_model\n",
        "\n",
        "    print(f\"\\n‚úÖ {model_name} tuning and training completed!\")\n",
        "\n",
        "# =========================\n",
        "# 6Ô∏è‚É£ Compare All Models\n",
        "# =========================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä FINAL COMPARISON OF ALL MODELS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create comparison table\n",
        "comparison_data = []\n",
        "for model_name, results in all_results.items():\n",
        "    comparison_data.append({\n",
        "        'Model': model_name,\n",
        "        'Tuning_F1_Macro': results['tuning_score'],\n",
        "        'Final_F1_Macro': results['final_metrics']['f1_macro'],\n",
        "        'Final_F1_Micro': results['final_metrics']['f1_micro'],\n",
        "        'Final_Hamming_Loss': results['final_metrics']['hamming_loss'],\n",
        "        'Final_Jaccard': results['final_metrics']['jaccard_score']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data).sort_values(\n",
        "    by='Final_F1_Macro', ascending=False\n",
        ")\n",
        "\n",
        "print(\"\\nüèÜ MODEL RANKINGS:\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Save comparison\n",
        "comparison_path = OUTPUT_DIR / \"model_comparison.csv\"\n",
        "comparison_df.to_csv(comparison_path, index=False)\n",
        "\n",
        "# Find best overall model\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "print(f\"\\nü•á BEST MODEL: {best_model_name}\")\n",
        "print(f\"   F1-Macro: {comparison_df.iloc[0]['Final_F1_Macro']:.4f}\")\n",
        "\n",
        "# =========================\n",
        "# 7Ô∏è‚É£ Save Best Model & Generate Submission\n",
        "# =========================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üíæ GENERATING FINAL PREDICTIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Use best model for final predictions\n",
        "best_model = best_models[best_model_name]\n",
        "\n",
        "# Retrain on full data\n",
        "print(f\"üîÑ Retraining {best_model_name} on full dataset...\")\n",
        "X_full_vec = vectorizer.fit_transform(X)\n",
        "best_model.fit(X_full_vec, y)\n",
        "\n",
        "# Generate test predictions\n",
        "print(\"üìù Generating test predictions...\")\n",
        "clean_test['final_text'] = clean_test['final_text'].fillna('')\n",
        "X_test_vec = vectorizer.transform(clean_test['final_text'])\n",
        "y_test_pred = best_model.predict(X_test_vec)\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame(y_test_pred, columns=emotions)\n",
        "submission['id'] = clean_test['id']\n",
        "submission = submission[['id'] + emotions]\n",
        "\n",
        "submission_path = OUTPUT_DIR / \"submission_optuna_tuned.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Submission saved: {submission_path}\")\n",
        "\n",
        "# =========================\n",
        "# 8Ô∏è‚É£ Save Summary Report\n",
        "# =========================\n",
        "summary = {\n",
        "    \"timestamp\": EXPERIMENT_CONFIG['timestamp'],\n",
        "    \"best_model\": best_model_name,\n",
        "    \"best_params\": all_results[best_model_name]['best_params'],\n",
        "    \"best_f1_macro\": float(all_results[best_model_name]['final_metrics']['f1_macro']),\n",
        "    \"all_results\": {k: {\n",
        "        'tuning_score': float(v['tuning_score']),\n",
        "        'final_f1_macro': float(v['final_metrics']['f1_macro'])\n",
        "    } for k, v in all_results.items()},\n",
        "    \"n_trials_per_model\": EXPERIMENT_CONFIG['n_trials']\n",
        "}\n",
        "\n",
        "summary_path = OUTPUT_DIR / \"tuning_summary.json\"\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump(summary, f, indent=4)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ HYPERPARAMETER TUNING PIPELINE COMPLETED!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nüìÅ All results saved in: {OUTPUT_DIR}\")\n",
        "print(f\"üèÜ Best Model: {best_model_name}\")\n",
        "print(f\"üìä Best F1-Macro: {summary['best_f1_macro']:.4f}\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1f7d0236ae9e493c9e48f4ec6eb3ad41",
            "934170f7fcc7492fa4a0e45e82d94162",
            "67a8c8a3ccac4ee497764aee9886f72b",
            "5e9b681f1e254d83a71a8114c53abf24",
            "5ff85d691c9644d3840a5c9e9b5a4c03",
            "160d40b4d30e40af997b8b2ce6f8f5db",
            "2001b96354294d6483f75f4ae5a7b349",
            "f2ad70d5850346a99b0125cd743b0521",
            "510efa2fb0204cdaaba9ded1a95bbc06",
            "b5c99205e7fd41ca94d3365c84bc1b79",
            "c646dd51d21949fbbad296dff9cb672c"
          ]
        },
        "id": "1L5eZIUz2jmP",
        "outputId": "7f253cbd-3fb7-4758-fc63-b16622e8644f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üöÄ HYPERPARAMETER TUNING WITH OPTUNA & W&B\n",
            "================================================================================\n",
            "\n",
            "üìê Vectorizing text data...\n",
            "‚úÖ Training samples: 3992\n",
            "‚úÖ Validation samples: 999\n",
            "‚úÖ Features: 5000\n",
            "\n",
            "================================================================================\n",
            "üöÄ STARTING HYPERPARAMETER TUNING PIPELINE\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üîß TUNING: LinearSVC\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251020_112433-gbc04bxd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/gbc04bxd' target=\"_blank\">optuna-LinearSVC-20251020_112432</a></strong> to <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/gbc04bxd' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/gbc04bxd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">optuna-LinearSVC-20251020_112432</strong> at: <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/gbc04bxd' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/gbc04bxd</a><br> View project at: <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251020_112433-gbc04bxd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251020_112435-pia5w0gs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/pia5w0gs' target=\"_blank\">stellar-shape-26</a></strong> to <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/pia5w0gs' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/pia5w0gs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-20 11:24:37,824] A new study created in memory with name: LinearSVC_tuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Running 50 trials...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f7d0236ae9e493c9e48f4ec6eb3ad41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-10-20 11:24:41,580] Trial 0 finished with value: 0.4736056213481762 and parameters: {'C': 0.5852445477749493, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 9000}. Best is trial 0 with value: 0.4736056213481762.\n",
            "[I 2025-10-20 11:24:41,714] Trial 1 finished with value: 0.4324431951688495 and parameters: {'C': 0.2912377316244013, 'loss': 'hinge', 'penalty': 'l2', 'max_iter': 8000}. Best is trial 0 with value: 0.4736056213481762.\n",
            "[I 2025-10-20 11:24:41,813] Trial 2 finished with value: 0.39805939993906697 and parameters: {'C': 0.041770057043509806, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 6000}. Best is trial 0 with value: 0.4736056213481762.\n",
            "[I 2025-10-20 11:24:43,574] Trial 3 finished with value: 0.4746066302796438 and parameters: {'C': 3.098020872593742, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 7000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:45,737] Trial 4 finished with value: 0.47052868614248033 and parameters: {'C': 3.494495095369014, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 10000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:45,816] Trial 5 finished with value: 0.3297433418202694 and parameters: {'C': 0.022213921626047992, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 4000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "‚ö†Ô∏è Error in evaluation: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
            "[I 2025-10-20 11:24:45,880] Trial 6 finished with value: 0.0 and parameters: {'C': 5.415988897256341, 'loss': 'hinge', 'penalty': 'l1', 'max_iter': 3000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:49,021] Trial 7 finished with value: 0.46874940991304664 and parameters: {'C': 7.991492981417997, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 8000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:49,092] Trial 8 finished with value: 0.1467680608365019 and parameters: {'C': 0.0023379678674687993, 'loss': 'hinge', 'penalty': 'l2', 'max_iter': 6000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:50,571] Trial 9 finished with value: 0.4624553744271278 and parameters: {'C': 23.010395517567115, 'loss': 'hinge', 'penalty': 'l2', 'max_iter': 10000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:53,000] Trial 10 finished with value: 0.4742669255979468 and parameters: {'C': 44.71010294259752, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:55,868] Trial 11 finished with value: 0.47076375151964367 and parameters: {'C': 54.425115278699295, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 3 with value: 0.4746066302796438.\n",
            "[I 2025-10-20 11:24:57,678] Trial 12 finished with value: 0.4747208357391865 and parameters: {'C': 58.88073868239131, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 12 with value: 0.4747208357391865.\n",
            "[I 2025-10-20 11:24:58,064] Trial 13 finished with value: 0.47670188727571006 and parameters: {'C': 0.9409847660476959, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 4000}. Best is trial 13 with value: 0.47670188727571006.\n",
            "[I 2025-10-20 11:24:58,184] Trial 14 finished with value: 0.4601643550315835 and parameters: {'C': 0.284025333823123, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 3000}. Best is trial 13 with value: 0.47670188727571006.\n",
            "[I 2025-10-20 11:25:04,903] Trial 15 finished with value: 0.4740796705644984 and parameters: {'C': 97.28161436237326, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 4000}. Best is trial 13 with value: 0.47670188727571006.\n",
            "[I 2025-10-20 11:25:05,159] Trial 16 finished with value: 0.48214576692022276 and parameters: {'C': 0.7143970187380617, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:05,572] Trial 17 finished with value: 0.47940762020657307 and parameters: {'C': 1.022309552267278, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 3000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "‚ö†Ô∏è Error in evaluation: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
            "[I 2025-10-20 11:25:05,648] Trial 18 finished with value: 0.0 and parameters: {'C': 0.061488030754411394, 'loss': 'hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:09,394] Trial 19 finished with value: 0.383627290675132 and parameters: {'C': 0.11401241334663663, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 3000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:09,969] Trial 20 finished with value: 0.4768821853491379 and parameters: {'C': 0.9375487299497591, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 5000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:10,514] Trial 21 finished with value: 0.47884789870239713 and parameters: {'C': 1.221858137213335, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 5000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:11,225] Trial 22 finished with value: 0.4786357122957896 and parameters: {'C': 1.5249139667668614, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:18,802] Trial 23 finished with value: 0.4699905883741301 and parameters: {'C': 12.868151338176597, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 5000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:18,863] Trial 24 finished with value: 0.1467680608365019 and parameters: {'C': 0.007520871988298617, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:18,941] Trial 25 finished with value: 0.4146969794856027 and parameters: {'C': 0.1684909578602665, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 4000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "‚ö†Ô∏è Error in evaluation: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
            "[I 2025-10-20 11:25:19,033] Trial 26 finished with value: 0.0 and parameters: {'C': 2.008545333870782, 'loss': 'hinge', 'penalty': 'l1', 'max_iter': 3000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:22,398] Trial 27 finished with value: 0.467926301437953 and parameters: {'C': 0.5112521800266016, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 5000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:22,516] Trial 28 finished with value: 0.3872545214551618 and parameters: {'C': 0.11545019061493568, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:23,031] Trial 29 finished with value: 0.47544956609293376 and parameters: {'C': 0.9386772449793341, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 7000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:23,252] Trial 30 finished with value: 0.4706291280526885 and parameters: {'C': 0.446862646117781, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 3000}. Best is trial 16 with value: 0.48214576692022276.\n",
            "[I 2025-10-20 11:25:24,518] Trial 31 finished with value: 0.4833628100959354 and parameters: {'C': 1.8990554437713822, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:25,389] Trial 32 finished with value: 0.48137290245946146 and parameters: {'C': 1.7386150816538464, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:26,790] Trial 33 finished with value: 0.4803067260521872 and parameters: {'C': 2.643670648841897, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:27,132] Trial 34 finished with value: 0.47824705416946794 and parameters: {'C': 2.9794415983024796, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 1000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:30,298] Trial 35 finished with value: 0.4732526392298883 and parameters: {'C': 9.696168127581052, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "‚ö†Ô∏è Error in evaluation: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
            "[I 2025-10-20 11:25:30,373] Trial 36 finished with value: 0.0 and parameters: {'C': 5.6311015471031665, 'loss': 'hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:32,611] Trial 37 finished with value: 0.4672472815452956 and parameters: {'C': 0.26310821442863225, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 2000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:33,922] Trial 38 finished with value: 0.4795972384128161 and parameters: {'C': 2.409251850033219, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:36,638] Trial 39 finished with value: 0.47419138416989226 and parameters: {'C': 18.401818500124683, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 2000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "‚ö†Ô∏è Error in evaluation: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
            "[I 2025-10-20 11:25:36,748] Trial 40 finished with value: 0.0 and parameters: {'C': 5.495061215633727, 'loss': 'hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:41,093] Trial 41 finished with value: 0.4765782364650475 and parameters: {'C': 2.676274044136593, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:43,580] Trial 42 finished with value: 0.47269670564283217 and parameters: {'C': 4.115236839505481, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 2000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:43,778] Trial 43 finished with value: 0.4732057511428156 and parameters: {'C': 0.5965040028662116, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 1000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:44,734] Trial 44 finished with value: 0.4813252940690716 and parameters: {'C': 1.960417926045229, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 9000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:44,901] Trial 45 finished with value: 0.4674900444405896 and parameters: {'C': 0.5079641310497254, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 10000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:45,109] Trial 46 finished with value: 0.4751770728717288 and parameters: {'C': 1.8301755615470607, 'loss': 'squared_hinge', 'penalty': 'l2', 'max_iter': 9000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:50,026] Trial 47 finished with value: 0.4716706333574409 and parameters: {'C': 8.194440265453679, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 3000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "‚ö†Ô∏è Error in evaluation: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
            "[I 2025-10-20 11:25:50,139] Trial 48 finished with value: 0.0 and parameters: {'C': 23.226246001634138, 'loss': 'hinge', 'penalty': 'l1', 'max_iter': 7000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "[I 2025-10-20 11:25:53,422] Trial 49 finished with value: 0.18686901186901186 and parameters: {'C': 0.024033421927064466, 'loss': 'squared_hinge', 'penalty': 'l1', 'max_iter': 9000}. Best is trial 31 with value: 0.4833628100959354.\n",
            "\n",
            "‚úÖ Best F1-Macro Score: 0.4834\n",
            "üìä Best Parameters:\n",
            "   ‚Ä¢ C: 1.8990554437713822\n",
            "   ‚Ä¢ loss: squared_hinge\n",
            "   ‚Ä¢ penalty: l1\n",
            "   ‚Ä¢ max_iter: 2000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>C</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ</td></tr><tr><td>best_f1_macro</td><td>‚ñÅ</td></tr><tr><td>f1_macro</td><td>‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÅ‚ñà‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñÉ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ</td></tr><tr><td>max_iter</td><td>‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñá‚ñÉ‚ñá</td></tr><tr><td>n_trials_completed</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>C</td><td>0.02403</td></tr><tr><td>best_f1_macro</td><td>0.48336</td></tr><tr><td>f1_macro</td><td>0.18687</td></tr><tr><td>loss</td><td>squared_hinge</td></tr><tr><td>max_iter</td><td>9000</td></tr><tr><td>n_trials_completed</td><td>50</td></tr><tr><td>penalty</td><td>l1</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stellar-shape-26</strong> at: <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/pia5w0gs' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/pia5w0gs</a><br> View project at: <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251020_112435-pia5w0gs/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üéØ FINAL TRAINING: LinearSVC\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251020_112555-xsi5o4nh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/xsi5o4nh' target=\"_blank\">final-LinearSVC-20251020_112432</a></strong> to <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/xsi5o4nh' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/xsi5o4nh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Training final model...\n",
            "\n",
            "üìä FINAL METRICS:\n",
            "   ‚Ä¢ F1-Macro: 0.4787\n",
            "   ‚Ä¢ F1-Micro: 0.5371\n",
            "   ‚Ä¢ F1-Weighted: 0.5360\n",
            "   ‚Ä¢ Hamming Loss: 0.2695\n",
            "   ‚Ä¢ Jaccard Score: 0.3775\n",
            "   ‚Ä¢ Subset Accuracy: 0.2322\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>anger_auc</td><td>‚ñÅ</td></tr><tr><td>anger_f1</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>anger_precision</td><td>‚ñÅ</td></tr><tr><td>anger_recall</td><td>‚ñÅ</td></tr><tr><td>f1_macro</td><td>‚ñÅ</td></tr><tr><td>f1_micro</td><td>‚ñÅ</td></tr><tr><td>f1_weighted</td><td>‚ñÅ</td></tr><tr><td>fear_auc</td><td>‚ñÅ</td></tr><tr><td>fear_f1</td><td>‚ñÅ‚ñÅ</td></tr><tr><td>fear_precision</td><td>‚ñÅ</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>anger_auc</td><td>0.72421</td></tr><tr><td>anger_f1</td><td>0.31527</td></tr><tr><td>anger_precision</td><td>0.34043</td></tr><tr><td>anger_recall</td><td>0.29358</td></tr><tr><td>f1_macro</td><td>0.4787</td></tr><tr><td>f1_micro</td><td>0.53714</td></tr><tr><td>f1_weighted</td><td>0.53602</td></tr><tr><td>fear_auc</td><td>0.6785</td></tr><tr><td>fear_f1</td><td>0.66667</td></tr><tr><td>fear_precision</td><td>0.69886</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">final-LinearSVC-20251020_112432</strong> at: <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/xsi5o4nh' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025/runs/xsi5o4nh</a><br> View project at: <a href='https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025' target=\"_blank\">https://wandb.ai/aiwithajay-indian-institute-of-technology-madras/23f3003030-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251020_112555-xsi5o4nh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ LinearSVC tuning and training completed!\n",
            "\n",
            "================================================================================\n",
            "üìä FINAL COMPARISON OF ALL MODELS\n",
            "================================================================================\n",
            "\n",
            "üèÜ MODEL RANKINGS:\n",
            "    Model  Tuning_F1_Macro  Final_F1_Macro  Final_F1_Micro  Final_Hamming_Loss  Final_Jaccard\n",
            "LinearSVC         0.483363        0.478698        0.537139            0.269469       0.377461\n",
            "\n",
            "ü•á BEST MODEL: LinearSVC\n",
            "   F1-Macro: 0.4787\n",
            "\n",
            "================================================================================\n",
            "üíæ GENERATING FINAL PREDICTIONS\n",
            "================================================================================\n",
            "üîÑ Retraining LinearSVC on full dataset...\n",
            "üìù Generating test predictions...\n",
            "‚úÖ Submission saved: outputs/optuna_tuning/submission_optuna_tuned.csv\n",
            "\n",
            "================================================================================\n",
            "‚úÖ HYPERPARAMETER TUNING PIPELINE COMPLETED!\n",
            "================================================================================\n",
            "\n",
            "üìÅ All results saved in: outputs/optuna_tuning\n",
            "üèÜ Best Model: LinearSVC\n",
            "üìä Best F1-Macro: 0.4787\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ts0kEWuvM8BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna-integration[wandb]"
      ],
      "metadata": {
        "id": "ztXFJJWwG5SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Je3-7P1ZG8_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}