{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nXTwgX_rOUIF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZWiF2-uWOvgF"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDEwqVePO61k",
        "outputId": "797c6985-6675-4f9b-d563-a35774ae4b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import html\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # 1. Decode HTML entities\n",
        "    text = html.unescape(text)\n",
        "\n",
        "    # 2. Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 3. Remove unwanted symbols/punctuation/digits\n",
        "    text = re.sub(r'[\"‚Äú‚Äù\\'\\*\\`~\\-=&;#\\\\/<>\\|\\[\\]\\(\\)_¬∂]', ' ', text)  # symbols\n",
        "    text = re.sub(r'\\.{2,}', ' ', text)  # multiple dots\n",
        "\n",
        "\n",
        "    # 4. Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "\n",
        "    # 6. Lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # 7. Join back to string\n",
        "    return ' '.join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aWBAz810QH8S"
      },
      "outputs": [],
      "source": [
        "df['clean_text']=df['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yCtNzpu4QVGA"
      },
      "outputs": [],
      "source": [
        "test['clean_text']=test['text'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "r3PTWh9qQW-E",
        "outputId": "6e625938-e32e-4757-fe14-91584d5867da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                               text  anger  fear  \\\n",
              "1660  1660  , the blisters on my feet ( the wound on my la...      0     1   \n",
              "2591  2591  , the blisters on my feet ( the wound on my la...      0     1   \n",
              "4270  4270  12:00 -- making lunch while a toddler hangs on...      0     1   \n",
              "3884  3884  12:00 -- making lunch while a toddler hangs on...      0     1   \n",
              "2085  2085  1991, about 8:00 a.m. in the morning on a satu...      0     1   \n",
              "...    ...                                                ...    ...   ...   \n",
              "3415  3415                                 your just at work.      0     0   \n",
              "3595  3595                                  your mom is nuts.      1     0   \n",
              "5495  5495                                  your mom is nuts.      1     0   \n",
              "1252  1252                       your story is really creepy.      0     1   \n",
              "6739  6739                       your story is really creepy.      0     1   \n",
              "\n",
              "      joy  sadness  surprise             emotions  \\\n",
              "1660    0        1         0   ['fear' 'sadness']   \n",
              "2591    0        1         0   ['fear' 'sadness']   \n",
              "4270    0        1         0   ['fear' 'sadness']   \n",
              "3884    0        1         0   ['fear' 'sadness']   \n",
              "2085    0        0         0             ['fear']   \n",
              "...   ...      ...       ...                  ...   \n",
              "3415    0        0         0                   []   \n",
              "3595    0        0         0            ['anger']   \n",
              "5495    0        0         0            ['anger']   \n",
              "1252    0        0         1  ['fear' 'surprise']   \n",
              "6739    0        0         1  ['fear' 'surprise']   \n",
              "\n",
              "                                             clean_text  \n",
              "1660  , the blister on my foot the wound on my large...  \n",
              "2591  , the blister on my foot the wound on my large...  \n",
              "4270  12:00 making lunch while a toddler hang on my ...  \n",
              "3884  12:00 making lunch while a toddler hang on my ...  \n",
              "2085  1991 , about 8:00 a.m. in the morning on a sat...  \n",
              "...                                                 ...  \n",
              "3415                                your just at work .  \n",
              "3595                                  your mom is nut .  \n",
              "5495                                  your mom is nut .  \n",
              "1252                      your story is really creepy .  \n",
              "6739                      your story is really creepy .  \n",
              "\n",
              "[3667 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e60fa18d-cbea-4459-95a6-8c965c52dafa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>anger</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>emotions</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1660</th>\n",
              "      <td>1660</td>\n",
              "      <td>, the blisters on my feet ( the wound on my la...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['fear' 'sadness']</td>\n",
              "      <td>, the blister on my foot the wound on my large...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2591</th>\n",
              "      <td>2591</td>\n",
              "      <td>, the blisters on my feet ( the wound on my la...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['fear' 'sadness']</td>\n",
              "      <td>, the blister on my foot the wound on my large...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4270</th>\n",
              "      <td>4270</td>\n",
              "      <td>12:00 -- making lunch while a toddler hangs on...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['fear' 'sadness']</td>\n",
              "      <td>12:00 making lunch while a toddler hang on my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3884</th>\n",
              "      <td>3884</td>\n",
              "      <td>12:00 -- making lunch while a toddler hangs on...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['fear' 'sadness']</td>\n",
              "      <td>12:00 making lunch while a toddler hang on my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085</th>\n",
              "      <td>2085</td>\n",
              "      <td>1991, about 8:00 a.m. in the morning on a satu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['fear']</td>\n",
              "      <td>1991 , about 8:00 a.m. in the morning on a sat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3415</th>\n",
              "      <td>3415</td>\n",
              "      <td>your just at work.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>your just at work .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3595</th>\n",
              "      <td>3595</td>\n",
              "      <td>your mom is nuts.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['anger']</td>\n",
              "      <td>your mom is nut .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5495</th>\n",
              "      <td>5495</td>\n",
              "      <td>your mom is nuts.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['anger']</td>\n",
              "      <td>your mom is nut .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>1252</td>\n",
              "      <td>your story is really creepy.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['fear' 'surprise']</td>\n",
              "      <td>your story is really creepy .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6739</th>\n",
              "      <td>6739</td>\n",
              "      <td>your story is really creepy.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['fear' 'surprise']</td>\n",
              "      <td>your story is really creepy .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3667 rows √ó 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e60fa18d-cbea-4459-95a6-8c965c52dafa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e60fa18d-cbea-4459-95a6-8c965c52dafa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e60fa18d-cbea-4459-95a6-8c965c52dafa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-906ab5c2-0049-4d18-b1c8-28de04c62558\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-906ab5c2-0049-4d18-b1c8-28de04c62558')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-906ab5c2-0049-4d18-b1c8-28de04c62558 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df\",\n  \"rows\": 3667,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1972,\n        \"min\": 0,\n        \"max\": 6826,\n        \"num_unique_values\": 3667,\n        \"samples\": [\n          1453,\n          4986,\n          865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1829,\n        \"samples\": [\n          \"every time i swiped for it it would disappear and reappear further in the woods.\",\n          \"(remember when okcupid had a blind date thing?\",\n          \"then she waved at me.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"joy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sadness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"['anger' 'fear']\",\n          \"['anger' 'fear' 'sadness']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1828,\n        \"samples\": [\n          \"every time i swiped for it it would disappear and reappear further in the wood .\",\n          \"remember why we were in this room , but it wa my grandmother master bedroom at the time .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df[df.duplicated(subset=['clean_text','emotions'],keep=False)].sort_values(by='clean_text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PHhB6dalQylq"
      },
      "outputs": [],
      "source": [
        "df=df.drop_duplicates(subset=['clean_text', 'emotions'], keep='first').reset_index()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRa5CiweR1aR",
        "outputId": "4ba673ed-2426-4609-c4aa-7984b1c92c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- Reproducibility ----------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------- Settings ----------\n",
        "EMOTION_COLS = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
        "\n",
        "\n",
        "X = df['clean_text'].astype(str)\n",
        "Y = df[EMOTION_COLS].astype(int)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=SEED, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for t in texts:\n",
        "        for tok in t.split():\n",
        "            counter[tok] += 1\n",
        "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for word, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab(x_train, min_freq=1)\n",
        "vocab_size = len(vocab)\n",
        "print(\"‚úÖ Vocab size:\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPxe_9hyfkf6",
        "outputId": "c6c8dc46-c314-48ce-f383-ca36d4b1cd28"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Vocab size: 6564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyxgbwAfXHz4",
        "outputId": "444f67b3-8290-4485-b054-96665ed1acf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Vocab size: 6564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/15 | Train Loss: 1.0828 | Val Loss: 0.6487 | Val F1: 0.1489\n",
            "‚úÖ Saved best model (F1=0.1489)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02/15 | Train Loss: 0.8568 | Val Loss: 0.8240 | Val F1: 0.2598\n",
            "‚úÖ Saved best model (F1=0.2598)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03/15 | Train Loss: 0.8393 | Val Loss: 0.6522 | Val F1: 0.1387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04/15 | Train Loss: 0.8935 | Val Loss: 1.0725 | Val F1: 0.2804\n",
            "‚úÖ Saved best model (F1=0.2804)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05/15 | Train Loss: 0.8400 | Val Loss: 0.7204 | Val F1: 0.1778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06/15 | Train Loss: 0.8401 | Val Loss: 0.7843 | Val F1: 0.2182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07/15 | Train Loss: 0.7658 | Val Loss: 0.5922 | Val F1: 0.1116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08/15 | Train Loss: 0.6768 | Val Loss: 0.6058 | Val F1: 0.1095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09/15 | Train Loss: 0.6426 | Val Loss: 0.6121 | Val F1: 0.2208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15 | Train Loss: 0.6332 | Val Loss: 0.5724 | Val F1: 0.1468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15 | Train Loss: 0.6065 | Val Loss: 0.6735 | Val F1: 0.1705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15 | Train Loss: 0.6136 | Val Loss: 0.6168 | Val F1: 0.1034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15 | Train Loss: 0.5943 | Val Loss: 0.5712 | Val F1: 0.1468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15 | Train Loss: 0.5921 | Val Loss: 0.5683 | Val F1: 0.1468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15 | Train Loss: 0.5760 | Val Loss: 0.5600 | Val F1: 0.1468\n",
            "üéØ Training finished. Best Val F1: 0.280402782084068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------- CONFIG -----------------\n",
        "EMOTION_COLS = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
        "MAX_LEN = 80           # üîº slightly longer for more context\n",
        "MIN_FREQ = 1\n",
        "BATCH_SIZE = 64        # üîº larger batch = better gradient estimates\n",
        "EMBED_DIM = 256        # üîº richer word features\n",
        "HIDDEN_DIM = 256       # üîº more capacity\n",
        "NUM_LAYERS = 3         # reduced for efficiency\n",
        "DROPOUT = 0.4          # slightly higher dropout for regularization\n",
        "NUM_EPOCHS = 15\n",
        "LEARNING_RATE = 0.07\n",
        "WEIGHT_DECAY = 1e-5    # üî• helps avoid overfitting (L2 regularization)\n",
        "GRAD_CLIP = 1.0        # üî• gradient clipping to stabilize RNN\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ----------------- BUILD VOCAB -----------------\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for t in texts:\n",
        "        for tok in t.split():\n",
        "            counter[tok] += 1\n",
        "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for word, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab(x_train, min_freq=MIN_FREQ)\n",
        "vocab_size = len(vocab)\n",
        "print(\"‚úÖ Vocab size:\", vocab_size)\n",
        "\n",
        "def text_to_ids(text, vocab):\n",
        "    return [vocab.get(tok, vocab['<UNK>']) for tok in text.split()]\n",
        "\n",
        "# ----------------- DATASET -----------------\n",
        "class RNNTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ids = text_to_ids(self.texts[idx], self.vocab)\n",
        "        label = torch.tensor(self.labels[idx]).float()\n",
        "        return torch.tensor(ids, dtype=torch.long), label\n",
        "\n",
        "def collate_batch(batch, max_len=MAX_LEN):\n",
        "    seqs, labels = zip(*batch)\n",
        "    lengths = [min(len(s), max_len) for s in seqs]\n",
        "    padded = torch.full((len(seqs), max_len), fill_value=vocab['<PAD>'], dtype=torch.long)\n",
        "    for i, s in enumerate(seqs):\n",
        "        truncated = s[:max_len]\n",
        "        padded[i, :len(truncated)] = truncated\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "    labels = torch.stack(labels)\n",
        "    return padded, lengths, labels\n",
        "\n",
        "train_ds = RNNTextDataset(x_train, y_train, vocab)\n",
        "val_ds   = RNNTextDataset(x_val,   y_val,   vocab)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda b: collate_batch(b, MAX_LEN))\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE*2, shuffle=False, collate_fn=lambda b: collate_batch(b, MAX_LEN))\n",
        "\n",
        "# ----------------- MODEL -----------------\n",
        "class VanillaRNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=1, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(input_size=embed_dim,\n",
        "                          hidden_size=hidden_dim,\n",
        "                          num_layers=num_layers,\n",
        "                          batch_first=True,\n",
        "                          nonlinearity='tanh',\n",
        "                          dropout=dropout if num_layers > 1 else 0.0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "        # üî• Xavier initialization for better convergence\n",
        "        for name, param in self.rnn.named_parameters():\n",
        "            if \"weight\" in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "            elif \"bias\" in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "    def forward(self, input_ids, lengths):\n",
        "        emb = self.embed(input_ids)\n",
        "        outputs, h_n = self.rnn(emb)\n",
        "        last_hidden = h_n[-1]\n",
        "        out = self.dropout(last_hidden)\n",
        "        logits = self.fc(out)\n",
        "        return logits\n",
        "\n",
        "model = VanillaRNNClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_classes=len(EMOTION_COLS),\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT\n",
        ").to(device)\n",
        "\n",
        "# ----------------- LOSS / OPTIMIZER -----------------\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)  # üî• AdamW > Adam\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
        "\n",
        "# ----------------- TRAIN / EVAL -----------------\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for input_ids, lengths, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
        "        input_ids, lengths, labels = input_ids.to(device), lengths.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, lengths)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)  # üî• prevent exploding gradients\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    preds_list, labels_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, lengths, labels in loader:\n",
        "            input_ids, lengths, labels = input_ids.to(device), lengths.to(device), labels.to(device)\n",
        "            logits = model(input_ids, lengths)\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            preds_list.append(probs)\n",
        "            labels_list.append(labels.cpu().numpy())\n",
        "\n",
        "    preds = np.vstack(preds_list)\n",
        "    labels = np.vstack(labels_list)\n",
        "    preds_bin = (preds >= 0.5).astype(int)\n",
        "    f1 = f1_score(labels, preds_bin, average='macro', zero_division=0)\n",
        "    return total_loss / len(loader), f1\n",
        "\n",
        "# ----------------- TRAINING LOOP -----------------\n",
        "best_val_f1 = 0.0\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_f1 = evaluate(model, val_loader, criterion)\n",
        "    scheduler.step(val_f1)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), \"best_vanilla_rnn.pth\")\n",
        "        print(f\"‚úÖ Saved best model (F1={best_val_f1:.4f})\")\n",
        "\n",
        "print(\"üéØ Training finished. Best Val F1:\", best_val_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6BVMU5eZeU",
        "outputId": "4b322bbe-a712-4522-cd44-4cc114779c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Train Loss: 0.5753 | Val F1: 0.1589\n",
            "‚úÖ Saved best model (F1: 0.15888636741019538 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50 | Train Loss: 0.5376 | Val F1: 0.2408\n",
            "‚úÖ Saved best model (F1: 0.24082745025699032 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50 | Train Loss: 0.5065 | Val F1: 0.3186\n",
            "‚úÖ Saved best model (F1: 0.31858049909342834 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50 | Train Loss: 0.4602 | Val F1: 0.3829\n",
            "‚úÖ Saved best model (F1: 0.3829316184621093 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50 | Train Loss: 0.4051 | Val F1: 0.4066\n",
            "‚úÖ Saved best model (F1: 0.40661196481067163 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50 | Train Loss: 0.3457 | Val F1: 0.4185\n",
            "‚úÖ Saved best model (F1: 0.41851014552458016 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50 | Train Loss: 0.2836 | Val F1: 0.4420\n",
            "‚úÖ Saved best model (F1: 0.44200443801832795 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50 | Train Loss: 0.2256 | Val F1: 0.4472\n",
            "‚úÖ Saved best model (F1: 0.4472125304194683 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50 | Train Loss: 0.1663 | Val F1: 0.4505\n",
            "‚úÖ Saved best model (F1: 0.4504866796559659 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50 | Train Loss: 0.1226 | Val F1: 0.4404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50 | Train Loss: 0.0973 | Val F1: 0.4560\n",
            "‚úÖ Saved best model (F1: 0.4560297798340091 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50 | Train Loss: 0.0653 | Val F1: 0.4431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50 | Train Loss: 0.0470 | Val F1: 0.4282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50 | Train Loss: 0.0396 | Val F1: 0.4351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50 | Train Loss: 0.0316 | Val F1: 0.4485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50 | Train Loss: 0.0258 | Val F1: 0.4450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50 | Train Loss: 0.0209 | Val F1: 0.4547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50 | Train Loss: 0.0208 | Val F1: 0.4337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50 | Train Loss: 0.0210 | Val F1: 0.4388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50 | Train Loss: 0.0252 | Val F1: 0.4499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50 | Train Loss: 0.0237 | Val F1: 0.4474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50 | Train Loss: 0.0182 | Val F1: 0.4254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50 | Train Loss: 0.0132 | Val F1: 0.4352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50 | Train Loss: 0.0115 | Val F1: 0.4533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50 | Train Loss: 0.0105 | Val F1: 0.4443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50 | Train Loss: 0.0093 | Val F1: 0.4370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50 | Train Loss: 0.0065 | Val F1: 0.4486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50 | Train Loss: 0.0147 | Val F1: 0.4486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50 | Train Loss: 0.0115 | Val F1: 0.4466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50 | Train Loss: 0.0087 | Val F1: 0.4521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50 | Train Loss: 0.0097 | Val F1: 0.4577\n",
            "‚úÖ Saved best model (F1: 0.4577198104055354 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50 | Train Loss: 0.0080 | Val F1: 0.4578\n",
            "‚úÖ Saved best model (F1: 0.45775551972953166 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50 | Train Loss: 0.0053 | Val F1: 0.4624\n",
            "‚úÖ Saved best model (F1: 0.46237754772246065 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50 | Train Loss: 0.0059 | Val F1: 0.4623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50 | Train Loss: 0.0065 | Val F1: 0.4617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50 | Train Loss: 0.0115 | Val F1: 0.4529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50 | Train Loss: 0.0121 | Val F1: 0.4345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50 | Train Loss: 0.0119 | Val F1: 0.4500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50 | Train Loss: 0.0087 | Val F1: 0.4588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50 | Train Loss: 0.0098 | Val F1: 0.4547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50 | Train Loss: 0.0071 | Val F1: 0.4507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50 | Train Loss: 0.0067 | Val F1: 0.4337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50 | Train Loss: 0.0060 | Val F1: 0.4524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50 | Train Loss: 0.0060 | Val F1: 0.4612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50 | Train Loss: 0.0058 | Val F1: 0.4496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50 | Train Loss: 0.0086 | Val F1: 0.4469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50 | Train Loss: 0.0217 | Val F1: 0.4390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50 | Train Loss: 0.0141 | Val F1: 0.4616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50 | Train Loss: 0.0065 | Val F1: 0.4510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50 | Train Loss: 0.0037 | Val F1: 0.4534\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- Hyperparameters ----------------\n",
        "EMOTION_COLS = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
        "MAX_LEN = 80\n",
        "MIN_FREQ = 1\n",
        "BATCH_SIZE = 64\n",
        "EMBED_DIM = 256\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.4\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 5e-4\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---------------- Vocabulary ----------------\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for t in texts:\n",
        "        for tok in t.split():\n",
        "            counter[tok] += 1\n",
        "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for word, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "def text_to_ids(text, vocab):\n",
        "    return [vocab.get(tok, vocab['<UNK>']) for tok in text.split()]\n",
        "\n",
        "# ---------------- Dataset ----------------\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, vocab=None):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values if labels is not None else None\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ids = text_to_ids(self.texts[idx], self.vocab)\n",
        "        if self.labels is not None:\n",
        "            label = torch.tensor(self.labels[idx]).float()\n",
        "            return torch.tensor(ids, dtype=torch.long), label\n",
        "        return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "def collate_batch(batch, max_len=MAX_LEN):\n",
        "    if isinstance(batch[0], tuple):\n",
        "        seqs, labels = zip(*batch)\n",
        "    else:\n",
        "        seqs = batch\n",
        "        labels = None\n",
        "    lengths = [min(len(s), max_len) for s in seqs]\n",
        "    padded = torch.full((len(seqs), max_len), fill_value=vocab['<PAD>'], dtype=torch.long)\n",
        "    for i, s in enumerate(seqs):\n",
        "        truncated = s[:max_len]\n",
        "        padded[i, :len(truncated)] = truncated\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "    if labels is not None:\n",
        "        labels = torch.stack(labels)\n",
        "        return padded, lengths, labels\n",
        "    return padded, lengths\n",
        "\n",
        "# ---------------- GRU Model ----------------\n",
        "class GRUClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=1, dropout=0.3, bidirectional=True):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, lengths):\n",
        "        emb = self.embed(input_ids)\n",
        "        packed_output, h_n = self.gru(emb)\n",
        "        # h_n: (num_layers * num_directions, batch, hidden)\n",
        "        if self.gru.bidirectional:\n",
        "            last_hidden = torch.cat((h_n[-2], h_n[-1]), dim=1)  # concat last forward + backward\n",
        "        else:\n",
        "            last_hidden = h_n[-1]\n",
        "        out = self.dropout(last_hidden)\n",
        "        logits = self.fc(out)\n",
        "        return logits\n",
        "\n",
        "# ---------------- Initialize ----------------\n",
        "vocab = build_vocab(x_train, min_freq=MIN_FREQ)\n",
        "vocab_size = len(vocab)\n",
        "model = GRUClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_classes=len(EMOTION_COLS),\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT,\n",
        "    bidirectional=True\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# ---------------- Training ----------------\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for input_ids, lengths, labels in tqdm(loader, leave=False):\n",
        "        input_ids, lengths, labels = input_ids.to(device), lengths.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, lengths)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)  # gradient clipping\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    preds_list, labels_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, lengths, labels in loader:\n",
        "            input_ids, lengths, labels = input_ids.to(device), lengths.to(device), labels.to(device)\n",
        "            logits = model(input_ids, lengths)\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            preds_list.append(probs)\n",
        "            labels_list.append(labels.cpu().numpy())\n",
        "    preds = np.vstack(preds_list)\n",
        "    labels = np.vstack(labels_list)\n",
        "    preds_bin = (preds >= 0.5).astype(int)\n",
        "    f1 = f1_score(labels, preds_bin, average='macro', zero_division=0)\n",
        "    return total_loss / len(loader), f1\n",
        "\n",
        "# ---------------- Dataloaders ----------------\n",
        "train_ds = TextDataset(x_train, y_train, vocab)\n",
        "val_ds   = TextDataset(x_val, y_val, vocab)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE*2, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "# ---------------- Training Loop ----------------\n",
        "best_val_f1 = 0.0\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_f1 = evaluate(model, val_loader, criterion)\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), \"gru_multi_label.pth\")\n",
        "        print(\"‚úÖ Saved best model (F1:\", best_val_f1, \")\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Dataset ---\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab, max_len=80):\n",
        "        self.texts = texts\n",
        "        self.labels = labels.values\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.texts.iloc[idx].split()\n",
        "        # numericalize + pad\n",
        "        ids = [self.vocab.get(w, self.vocab[\"<unk>\"]) for w in tokens[:self.max_len]]\n",
        "        ids += [self.vocab[\"<pad>\"]] * (self.max_len - len(ids))\n",
        "        return torch.tensor(ids), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# --- Model ---\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "            bidirectional=True  # bidirectional LSTM\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)  # (batch, seq, embed_dim)\n",
        "        out, (h_n, c_n) = self.lstm(emb)  # h_n: (num_layers*2, batch, hidden)\n",
        "        last_hidden = torch.cat((h_n[-2], h_n[-1]), dim=1)  # concat forward + backward\n",
        "        out = self.layer_norm(last_hidden)\n",
        "        out = self.dropout(out)\n",
        "        logits = self.fc(out)\n",
        "        return logits\n",
        "\n",
        "# --- Training Utilities ---\n",
        "def train_model(model, train_loader, val_loader, epochs=10, lr=1e-3, device='cuda'):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch in val_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                logits = model(x_batch)\n",
        "                preds = torch.sigmoid(logits).cpu().numpy() > 0.5\n",
        "                val_preds.extend(preds)\n",
        "                val_labels.extend(y_batch.numpy())\n",
        "\n",
        "        f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "        print(f\"Epoch {epoch+1:02d} | Train Loss: {avg_train_loss:.4f} | Val F1: {f1:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            torch.save(model.state_dict(), \"best_lstm_model.pt\")\n",
        "            print(f\"‚úÖ Saved best model (F1={f1:.4f})\")\n",
        "\n",
        "# --- Vocabulary Builder ---\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    from collections import Counter\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(text.split())\n",
        "\n",
        "    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
        "    for word, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = len(vocab)\n",
        "    return vocab\n"
      ],
      "metadata": {
        "id": "TYIJQNVGYEJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Build vocab\n",
        "vocab = build_vocab(x_train, min_freq=2)\n",
        "print(\"‚úÖ Vocab size:\", len(vocab))\n",
        "\n",
        "# 2. Prepare datasets\n",
        "train_dataset = TextDataset(x_train, y_train, vocab)\n",
        "val_dataset = TextDataset(x_val, y_val, vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "# 3. Initialize and train\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = LSTMClassifier(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=128,\n",
        "    hidden_dim=128,\n",
        "    num_classes=y_train.shape[1],\n",
        "    num_layers=2,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "train_model(model, train_loader, val_loader, epochs=20, lr=1e-3, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDUmDMwPYkYN",
        "outputId": "36efd869-58ee-49be-c685-0794d4c60e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Vocab size: 3043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 64.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 0.5834 | Val F1: 0.1358\n",
            "‚úÖ Saved best model (F1=0.1358)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 79.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | Train Loss: 0.5515 | Val F1: 0.2658\n",
            "‚úÖ Saved best model (F1=0.2658)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 79.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | Train Loss: 0.5225 | Val F1: 0.2808\n",
            "‚úÖ Saved best model (F1=0.2808)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 78.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | Train Loss: 0.4890 | Val F1: 0.3291\n",
            "‚úÖ Saved best model (F1=0.3291)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 78.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | Train Loss: 0.4430 | Val F1: 0.3915\n",
            "‚úÖ Saved best model (F1=0.3915)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 75.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | Train Loss: 0.3926 | Val F1: 0.3999\n",
            "‚úÖ Saved best model (F1=0.3999)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 72.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 | Train Loss: 0.3335 | Val F1: 0.4086\n",
            "‚úÖ Saved best model (F1=0.4086)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 70.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08 | Train Loss: 0.2808 | Val F1: 0.4329\n",
            "‚úÖ Saved best model (F1=0.4329)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 77.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09 | Train Loss: 0.2230 | Val F1: 0.4266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 78.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Train Loss: 0.1911 | Val F1: 0.4344\n",
            "‚úÖ Saved best model (F1=0.4344)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 78.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | Train Loss: 0.1408 | Val F1: 0.4258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 77.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | Train Loss: 0.1146 | Val F1: 0.4515\n",
            "‚úÖ Saved best model (F1=0.4515)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 78.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 | Train Loss: 0.0854 | Val F1: 0.4431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 78.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 | Train Loss: 0.0756 | Val F1: 0.4378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 78.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | Train Loss: 0.0567 | Val F1: 0.4393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 77.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 | Train Loss: 0.0471 | Val F1: 0.4565\n",
            "‚úÖ Saved best model (F1=0.4565)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 77.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 | Train Loss: 0.0421 | Val F1: 0.4494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 77.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 | Train Loss: 0.0390 | Val F1: 0.4509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 73.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 | Train Loss: 0.0299 | Val F1: 0.4590\n",
            "‚úÖ Saved best model (F1=0.4590)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 69.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | Train Loss: 0.0273 | Val F1: 0.4517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lyvv4D6hYq-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU + ATTENTion"
      ],
      "metadata": {
        "id": "a0u4rDAQY9d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- Hyperparameters ----------------\n",
        "EMOTION_COLS = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
        "MAX_LEN = 80\n",
        "MIN_FREQ = 1\n",
        "BATCH_SIZE = 64\n",
        "EMBED_DIM = 256\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.4\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 5e-4\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---------------- Vocabulary ----------------\n",
        "def build_vocab(texts, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for t in texts:\n",
        "        for tok in t.split():\n",
        "            counter[tok] += 1\n",
        "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for word, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "def text_to_ids(text, vocab):\n",
        "    return [vocab.get(tok, vocab['<UNK>']) for tok in text.split()]\n",
        "\n",
        "# ---------------- Dataset ----------------\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, vocab=None):\n",
        "        self.texts = texts.tolist()\n",
        "        self.labels = labels.values if labels is not None else None\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ids = text_to_ids(self.texts[idx], self.vocab)\n",
        "        if self.labels is not None:\n",
        "            label = torch.tensor(self.labels[idx]).float()\n",
        "            return torch.tensor(ids, dtype=torch.long), label\n",
        "        return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "def collate_batch(batch, max_len=MAX_LEN):\n",
        "    if isinstance(batch[0], tuple):\n",
        "        seqs, labels = zip(*batch)\n",
        "    else:\n",
        "        seqs = batch\n",
        "        labels = None\n",
        "    lengths = [min(len(s), max_len) for s in seqs]\n",
        "    padded = torch.full((len(seqs), max_len), fill_value=vocab['<PAD>'], dtype=torch.long)\n",
        "    for i, s in enumerate(seqs):\n",
        "        truncated = s[:max_len]\n",
        "        padded[i, :len(truncated)] = truncated\n",
        "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
        "    if labels is not None:\n",
        "        labels = torch.stack(labels)\n",
        "        return padded, lengths, labels\n",
        "    return padded, lengths\n",
        "\n",
        "# ---------------- GRU + Attention Model ----------------\n",
        "class GRUAttentionClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=1, dropout=0.3, bidirectional=True):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attention = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, 1)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, lengths):\n",
        "        emb = self.embed(input_ids)\n",
        "        packed_output, h_n = self.gru(emb)  # outputs: (batch, seq_len, hidden*directions)\n",
        "\n",
        "        # ---------------- Attention ----------------\n",
        "        attn_weights = self.attention(packed_output).squeeze(-1)  # (batch, seq_len)\n",
        "        mask = (input_ids != 0)  # ignore PAD tokens\n",
        "        attn_weights[~mask] = float('-inf')\n",
        "        attn_scores = torch.softmax(attn_weights, dim=1).unsqueeze(-1)  # (batch, seq_len, 1)\n",
        "        weighted_output = (packed_output * attn_scores).sum(dim=1)      # (batch, hidden*directions)\n",
        "\n",
        "        out = self.dropout(weighted_output)\n",
        "        logits = self.fc(out)\n",
        "        return logits\n",
        "\n",
        "# ---------------- Initialize ----------------\n",
        "vocab = build_vocab(x_train, min_freq=MIN_FREQ)\n",
        "vocab_size = len(vocab)\n",
        "model = GRUAttentionClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_classes=len(EMOTION_COLS),\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT,\n",
        "    bidirectional=True\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# ---------------- Train / Eval ----------------\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for input_ids, lengths, labels in tqdm(loader, leave=False):\n",
        "        input_ids, lengths, labels = input_ids.to(device), lengths.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, lengths)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    preds_list, labels_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for input_ids, lengths, labels in loader:\n",
        "            input_ids, lengths, labels = input_ids.to(device), lengths.to(device), labels.to(device)\n",
        "            logits = model(input_ids, lengths)\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            preds_list.append(probs)\n",
        "            labels_list.append(labels.cpu().numpy())\n",
        "    preds = np.vstack(preds_list)\n",
        "    labels = np.vstack(labels_list)\n",
        "    preds_bin = (preds >= 0.5).astype(int)\n",
        "    f1 = f1_score(labels, preds_bin, average='macro', zero_division=0)\n",
        "    return total_loss / len(loader), f1\n",
        "\n",
        "# ---------------- Dataloaders ----------------\n",
        "train_ds = TextDataset(x_train, y_train, vocab)\n",
        "val_ds   = TextDataset(x_val, y_val, vocab)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE*2, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "# ---------------- Training Loop ----------------\n",
        "best_val_f1 = 0.0\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_f1 = evaluate(model, val_loader, criterion)\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), \"gru_attention_multi_label.pth\")\n",
        "        print(\"‚úÖ Saved best model (F1:\", best_val_f1, \")\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUEgyQrqZC_R",
        "outputId": "99970b54-2b10-4cce-f4ca-2b1c90506728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Train Loss: 0.5637 | Val F1: 0.2276\n",
            "‚úÖ Saved best model (F1: 0.22757210377278198 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50 | Train Loss: 0.5257 | Val F1: 0.3147\n",
            "‚úÖ Saved best model (F1: 0.31468548803118307 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50 | Train Loss: 0.4823 | Val F1: 0.3633\n",
            "‚úÖ Saved best model (F1: 0.3633344476727465 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50 | Train Loss: 0.4197 | Val F1: 0.4408\n",
            "‚úÖ Saved best model (F1: 0.4407900749073555 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50 | Train Loss: 0.3502 | Val F1: 0.4537\n",
            "‚úÖ Saved best model (F1: 0.4537360456591936 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50 | Train Loss: 0.2772 | Val F1: 0.4679\n",
            "‚úÖ Saved best model (F1: 0.4678892446196373 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50 | Train Loss: 0.2020 | Val F1: 0.4665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50 | Train Loss: 0.1444 | Val F1: 0.4662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50 | Train Loss: 0.0921 | Val F1: 0.4697\n",
            "‚úÖ Saved best model (F1: 0.46971098658003924 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50 | Train Loss: 0.0641 | Val F1: 0.4743\n",
            "‚úÖ Saved best model (F1: 0.47434508481901105 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50 | Train Loss: 0.0450 | Val F1: 0.4623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50 | Train Loss: 0.0284 | Val F1: 0.4571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50 | Train Loss: 0.0206 | Val F1: 0.4492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50 | Train Loss: 0.0175 | Val F1: 0.4499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50 | Train Loss: 0.0185 | Val F1: 0.4511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50 | Train Loss: 0.0159 | Val F1: 0.4669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50 | Train Loss: 0.0109 | Val F1: 0.4705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50 | Train Loss: 0.0096 | Val F1: 0.4598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50 | Train Loss: 0.0059 | Val F1: 0.4576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50 | Train Loss: 0.0055 | Val F1: 0.4671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50 | Train Loss: 0.0138 | Val F1: 0.4639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50 | Train Loss: 0.0278 | Val F1: 0.4626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50 | Train Loss: 0.0292 | Val F1: 0.4535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50 | Train Loss: 0.0197 | Val F1: 0.4581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50 | Train Loss: 0.0093 | Val F1: 0.4588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50 | Train Loss: 0.0054 | Val F1: 0.4617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50 | Train Loss: 0.0039 | Val F1: 0.4601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50 | Train Loss: 0.0023 | Val F1: 0.4654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50 | Train Loss: 0.0018 | Val F1: 0.4626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50 | Train Loss: 0.0013 | Val F1: 0.4614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50 | Train Loss: 0.0015 | Val F1: 0.4578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50 | Train Loss: 0.0015 | Val F1: 0.4588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50 | Train Loss: 0.0018 | Val F1: 0.4602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50 | Train Loss: 0.0016 | Val F1: 0.4531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50 | Train Loss: 0.0026 | Val F1: 0.4593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50 | Train Loss: 0.0034 | Val F1: 0.4690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50 | Train Loss: 0.0022 | Val F1: 0.4542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50 | Train Loss: 0.0028 | Val F1: 0.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50 | Train Loss: 0.0155 | Val F1: 0.4591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50 | Train Loss: 0.0454 | Val F1: 0.4590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50 | Train Loss: 0.0501 | Val F1: 0.4451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50 | Train Loss: 0.0160 | Val F1: 0.4696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50 | Train Loss: 0.0059 | Val F1: 0.4585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50 | Train Loss: 0.0028 | Val F1: 0.4580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50 | Train Loss: 0.0019 | Val F1: 0.4480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50 | Train Loss: 0.0015 | Val F1: 0.4593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50 | Train Loss: 0.0015 | Val F1: 0.4589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50 | Train Loss: 0.0015 | Val F1: 0.4560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50 | Train Loss: 0.0011 | Val F1: 0.4575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50 | Train Loss: 0.0010 | Val F1: 0.4576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multihead Attention\n"
      ],
      "metadata": {
        "id": "kOugAlPFaCXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Model Definition\n",
        "# ------------------------------------------------------------------\n",
        "class GRU_AttentionModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.4):\n",
        "        super(GRU_AttentionModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.embedding_dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        # Multi-head self-attention\n",
        "        self.multihead_attn = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim * 2,  # bidirectional GRU\n",
        "            num_heads=4,\n",
        "            dropout=0.3,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
        "\n",
        "        # MLP classifier head\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths=None):\n",
        "        emb = self.embedding_dropout(self.embedding(x))  # (batch, seq, emb)\n",
        "        packed_output, _ = self.gru(emb)\n",
        "\n",
        "        # Multi-head self-attention (Q=K=V)\n",
        "        attn_output, _ = self.multihead_attn(packed_output, packed_output, packed_output)\n",
        "        attn_output = self.layer_norm(attn_output + packed_output)\n",
        "\n",
        "        # Mean pooling over time dimension\n",
        "        mean_output = attn_output.mean(dim=1)\n",
        "\n",
        "        logits = self.fc(mean_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Dataset Class\n",
        "# ------------------------------------------------------------------\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y, vocab, max_len):\n",
        "        self.X = X\n",
        "        self.y = y.values\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def text_to_seq(self, text):\n",
        "        tokens = text.split()\n",
        "        seq = [self.vocab.get(tok, self.vocab[\"<UNK>\"]) for tok in tokens[:self.max_len]]\n",
        "        seq += [self.vocab[\"<PAD>\"]] * (self.max_len - len(seq))\n",
        "        return torch.tensor(seq, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.text_to_seq(self.X.iloc[idx]), torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Training Utilities\n",
        "# ------------------------------------------------------------------\n",
        "def train_epoch(model, loader, optimizer, criterion, device, scheduler=None, clip=5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "        optimizer.step()\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def eval_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds.append(torch.sigmoid(logits).cpu())\n",
        "            targets.append(y_batch.cpu())\n",
        "\n",
        "    preds = torch.cat(preds)\n",
        "    targets = torch.cat(targets)\n",
        "    f1 = f1_score(targets.numpy() > 0.5, preds.numpy() > 0.5, average=\"macro\")\n",
        "    return total_loss / len(loader), f1\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Training Script\n",
        "# ------------------------------------------------------------------\n",
        "def train_model(vocab, x_train, y_train, x_val, y_val, num_classes):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    MAX_LEN = 100\n",
        "    EMBED_DIM = 256\n",
        "    HIDDEN_DIM = 256\n",
        "    NUM_LAYERS = 2\n",
        "    DROPOUT = 0.4\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 50\n",
        "    LEARNING_RATE = 5e-4\n",
        "\n",
        "    train_ds = TextDataset(x_train, y_train, vocab, MAX_LEN)\n",
        "    val_ds = TextDataset(x_val, y_val, vocab, MAX_LEN)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = GRU_AttentionModel(len(vocab), EMBED_DIM, HIDDEN_DIM, num_classes, NUM_LAYERS, DROPOUT).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=1e-3, epochs=EPOCHS, steps_per_epoch=len(train_loader)\n",
        "    )\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, scheduler)\n",
        "        val_loss, val_f1 = eval_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch:02d}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(f\"‚úÖ Saved best model (F1={val_f1:.4f})\")\n",
        "\n",
        "    print(f\"Training complete. Best F1: {best_f1:.4f}\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Run Training\n",
        "# ------------------------------------------------------------------\n",
        "# Assuming you already have:\n",
        "# x_train, x_test, y_train, y_test, vocab\n",
        "# and vocab contains \"<PAD>\" and \"<UNK>\"\n",
        "train_model(vocab, x_train, y_train, x_val, y_val, num_classes=y_train.shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cceKmnASZT-t",
        "outputId": "2a11cd9b-a72a-4f5e-de79-2e21e5c81507"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/50 | Train Loss: 0.5919 | Val F1: 0.1468\n",
            "‚úÖ Saved best model (F1=0.1468)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02/50 | Train Loss: 0.5737 | Val F1: 0.1468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03/50 | Train Loss: 0.5690 | Val F1: 0.1468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04/50 | Train Loss: 0.5618 | Val F1: 0.2492\n",
            "‚úÖ Saved best model (F1=0.2492)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05/50 | Train Loss: 0.5567 | Val F1: 0.2462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06/50 | Train Loss: 0.5489 | Val F1: 0.2022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07/50 | Train Loss: 0.5411 | Val F1: 0.2765\n",
            "‚úÖ Saved best model (F1=0.2765)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08/50 | Train Loss: 0.5367 | Val F1: 0.3038\n",
            "‚úÖ Saved best model (F1=0.3038)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09/50 | Train Loss: 0.5192 | Val F1: 0.3386\n",
            "‚úÖ Saved best model (F1=0.3386)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50 | Train Loss: 0.5080 | Val F1: 0.3485\n",
            "‚úÖ Saved best model (F1=0.3485)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50 | Train Loss: 0.4936 | Val F1: 0.3184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50 | Train Loss: 0.4900 | Val F1: 0.3614\n",
            "‚úÖ Saved best model (F1=0.3614)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50 | Train Loss: 0.4686 | Val F1: 0.3161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50 | Train Loss: 0.4552 | Val F1: 0.4100\n",
            "‚úÖ Saved best model (F1=0.4100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50 | Train Loss: 0.4309 | Val F1: 0.4214\n",
            "‚úÖ Saved best model (F1=0.4214)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50 | Train Loss: 0.4072 | Val F1: 0.4135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50 | Train Loss: 0.3880 | Val F1: 0.4521\n",
            "‚úÖ Saved best model (F1=0.4521)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50 | Train Loss: 0.3613 | Val F1: 0.4377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50 | Train Loss: 0.3388 | Val F1: 0.4414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50 | Train Loss: 0.3154 | Val F1: 0.4625\n",
            "‚úÖ Saved best model (F1=0.4625)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50 | Train Loss: 0.2913 | Val F1: 0.4627\n",
            "‚úÖ Saved best model (F1=0.4627)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50 | Train Loss: 0.2681 | Val F1: 0.4537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50 | Train Loss: 0.2489 | Val F1: 0.4363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50 | Train Loss: 0.2196 | Val F1: 0.4484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50 | Train Loss: 0.1984 | Val F1: 0.4733\n",
            "‚úÖ Saved best model (F1=0.4733)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50 | Train Loss: 0.1833 | Val F1: 0.4563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50 | Train Loss: 0.1595 | Val F1: 0.4592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50 | Train Loss: 0.1493 | Val F1: 0.4482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50 | Train Loss: 0.1263 | Val F1: 0.4679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50 | Train Loss: 0.1226 | Val F1: 0.4674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50 | Train Loss: 0.1094 | Val F1: 0.4588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50 | Train Loss: 0.0973 | Val F1: 0.4438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50 | Train Loss: 0.0823 | Val F1: 0.4565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50 | Train Loss: 0.0834 | Val F1: 0.4615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50 | Train Loss: 0.0729 | Val F1: 0.4457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50 | Train Loss: 0.0674 | Val F1: 0.4666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50 | Train Loss: 0.0613 | Val F1: 0.4640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50 | Train Loss: 0.0548 | Val F1: 0.4626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50 | Train Loss: 0.0477 | Val F1: 0.4679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50 | Train Loss: 0.0451 | Val F1: 0.4679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50 | Train Loss: 0.0475 | Val F1: 0.4627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50 | Train Loss: 0.0411 | Val F1: 0.4710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50 | Train Loss: 0.0382 | Val F1: 0.4627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50 | Train Loss: 0.0384 | Val F1: 0.4678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50 | Train Loss: 0.0387 | Val F1: 0.4652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50 | Train Loss: 0.0322 | Val F1: 0.4674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50 | Train Loss: 0.0315 | Val F1: 0.4714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2732404525.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m# x_train, x_test, y_train, y_test, vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m# and vocab contains \"<PAD>\" and \"<UNK>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2732404525.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(vocab, x_train, y_train, x_val, y_val, num_classes)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mbest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2732404525.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion, device, scheduler, clip)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install optuna\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "import optuna\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Model Definition\n",
        "# ------------------------------------------------------------------\n",
        "class GRU_AttentionModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.4):\n",
        "        super(GRU_AttentionModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.embedding_dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=embed_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        # Multi-head self-attention\n",
        "        self.multihead_attn = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_dim * 2,\n",
        "            num_heads=4,\n",
        "            dropout=0.3,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
        "\n",
        "        # MLP classifier head\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths=None):\n",
        "        emb = self.embedding_dropout(self.embedding(x))\n",
        "        packed_output, _ = self.gru(emb)\n",
        "        attn_output, _ = self.multihead_attn(packed_output, packed_output, packed_output)\n",
        "        attn_output = self.layer_norm(attn_output + packed_output)\n",
        "        mean_output = attn_output.mean(dim=1)\n",
        "        logits = self.fc(mean_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Dataset\n",
        "# ------------------------------------------------------------------\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y, vocab, max_len):\n",
        "        self.X = X\n",
        "        self.y = y.values\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def text_to_seq(self, text):\n",
        "        tokens = text.split()\n",
        "        seq = [self.vocab.get(tok, self.vocab[\"<UNK>\"]) for tok in tokens[:self.max_len]]\n",
        "        seq += [self.vocab[\"<PAD>\"]] * (self.max_len - len(seq))\n",
        "        return torch.tensor(seq, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.text_to_seq(self.X.iloc[idx]), torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Train / Eval\n",
        "# ------------------------------------------------------------------\n",
        "def train_epoch(model, loader, optimizer, criterion, device, scheduler=None, clip=5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "        optimizer.step()\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def eval_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            preds.append(torch.sigmoid(logits).cpu())\n",
        "            targets.append(y_batch.cpu())\n",
        "    preds = torch.cat(preds)\n",
        "    targets = torch.cat(targets)\n",
        "    f1 = f1_score(targets.numpy() > 0.5, preds.numpy() > 0.5, average=\"macro\")\n",
        "    return total_loss / len(loader), f1\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Optuna Objective Function\n",
        "# ------------------------------------------------------------------\n",
        "def objective(trial):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # üî∏ Hyperparameters to tune\n",
        "    EMBED_DIM = trial.suggest_categorical(\"embed_dim\", [128, 256, 300])\n",
        "    HIDDEN_DIM = trial.suggest_categorical(\"hidden_dim\", [128, 256, 384])\n",
        "    NUM_LAYERS = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "    DROPOUT = trial.suggest_float(\"dropout\", 0.2, 0.6)\n",
        "    LR = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
        "    BATCH_SIZE = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "    MAX_LEN = 100\n",
        "    EPOCHS = 20  # keep small for tuning speed\n",
        "\n",
        "    # Build datasets\n",
        "    train_ds = TextDataset(x_train, y_train, vocab, MAX_LEN)\n",
        "    val_ds = TextDataset(x_val, y_val, vocab, MAX_LEN)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = GRU_AttentionModel(len(vocab), EMBED_DIM, HIDDEN_DIM, y_train.shape[1], NUM_LAYERS, DROPOUT).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_f1 = eval_epoch(model, val_loader, criterion, device)\n",
        "        trial.report(val_f1, epoch)\n",
        "\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "\n",
        "    return best_f1\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ Run Optuna Tuning\n",
        "# ------------------------------------------------------------------\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20, timeout=None)\n",
        "\n",
        "print(\"\\nüéØ Best Trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  F1 Score: {trial.value:.4f}\")\n",
        "print(\"  Params:\")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# üîπ (Optional) Retrain best model with tuned params\n",
        "# ------------------------------------------------------------------\n",
        "best_params = study.best_trial.params\n",
        "print(\"\\nRetraining with best params...\")\n",
        "\n",
        "train_model(\n",
        "    vocab,\n",
        "    x_train,\n",
        "    y_train,\n",
        "    x_val,\n",
        "    y_val,\n",
        "    num_classes=y_train.shape[1],\n",
        ")\n"
      ],
      "metadata": {
        "id": "RsHe5QYMaGJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a23920-b3e1-4dcc-88f7-e34c1f390211"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-22 06:30:39,734] A new study created in memory with name: no-name-3198626d-5a80-43ba-87b6-7e629279e4ed\n",
            "[I 2025-10-22 06:31:23,255] Trial 0 finished with value: 0.4481769298200516 and parameters: {'embed_dim': 256, 'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.22593063025338786, 'lr': 0.0017149289930817563, 'batch_size': 128}. Best is trial 0 with value: 0.4481769298200516.\n",
            "[I 2025-10-22 06:32:01,425] Trial 1 finished with value: 0.4755266850339118 and parameters: {'embed_dim': 300, 'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.24770800542716534, 'lr': 0.00029483725734426666, 'batch_size': 32}. Best is trial 1 with value: 0.4755266850339118.\n",
            "[I 2025-10-22 06:32:29,399] Trial 2 finished with value: 0.4803402155373063 and parameters: {'embed_dim': 300, 'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.27394124734819464, 'lr': 0.0010634558316564187, 'batch_size': 64}. Best is trial 2 with value: 0.4803402155373063.\n",
            "[I 2025-10-22 06:33:15,068] Trial 3 finished with value: 0.3958537433220156 and parameters: {'embed_dim': 256, 'hidden_dim': 256, 'num_layers': 1, 'dropout': 0.5642622586103371, 'lr': 0.00265792594599784, 'batch_size': 64}. Best is trial 2 with value: 0.4803402155373063.\n",
            "[I 2025-10-22 06:33:42,485] Trial 4 finished with value: 0.4907634521661663 and parameters: {'embed_dim': 300, 'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.48683977124012534, 'lr': 0.0016421109262960908, 'batch_size': 128}. Best is trial 4 with value: 0.4907634521661663.\n",
            "[I 2025-10-22 06:33:51,067] Trial 5 pruned. \n",
            "[I 2025-10-22 06:34:00,973] Trial 6 pruned. \n",
            "[I 2025-10-22 06:34:02,980] Trial 7 pruned. \n",
            "[I 2025-10-22 06:34:06,970] Trial 8 pruned. \n",
            "[I 2025-10-22 06:34:47,752] Trial 9 pruned. \n",
            "[I 2025-10-22 06:34:49,202] Trial 10 pruned. \n",
            "[I 2025-10-22 06:34:50,595] Trial 11 pruned. \n",
            "[I 2025-10-22 06:34:51,996] Trial 12 pruned. \n",
            "[I 2025-10-22 06:34:53,419] Trial 13 pruned. \n",
            "[I 2025-10-22 06:34:56,562] Trial 14 pruned. \n",
            "[I 2025-10-22 06:34:59,369] Trial 15 pruned. \n",
            "[I 2025-10-22 06:35:05,999] Trial 16 pruned. \n",
            "[I 2025-10-22 06:35:07,795] Trial 17 pruned. \n",
            "[I 2025-10-22 06:35:09,354] Trial 18 pruned. \n",
            "[I 2025-10-22 06:35:16,973] Trial 19 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ Best Trial:\n",
            "  F1 Score: 0.4908\n",
            "  Params:\n",
            "    embed_dim: 300\n",
            "    hidden_dim: 128\n",
            "    num_layers: 2\n",
            "    dropout: 0.48683977124012534\n",
            "    lr: 0.0016421109262960908\n",
            "    batch_size: 128\n",
            "\n",
            "Retraining with best params...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/50 | Train Loss: 0.5948 | Val F1: 0.1469\n",
            "‚úÖ Saved best model (F1=0.1469)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02/50 | Train Loss: 0.5742 | Val F1: 0.1468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03/50 | Train Loss: 0.5698 | Val F1: 0.1465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04/50 | Train Loss: 0.5624 | Val F1: 0.2373\n",
            "‚úÖ Saved best model (F1=0.2373)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05/50 | Train Loss: 0.5554 | Val F1: 0.2625\n",
            "‚úÖ Saved best model (F1=0.2625)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06/50 | Train Loss: 0.5468 | Val F1: 0.2347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07/50 | Train Loss: 0.5339 | Val F1: 0.2767\n",
            "‚úÖ Saved best model (F1=0.2767)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08/50 | Train Loss: 0.5284 | Val F1: 0.2843\n",
            "‚úÖ Saved best model (F1=0.2843)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09/50 | Train Loss: 0.5126 | Val F1: 0.3224\n",
            "‚úÖ Saved best model (F1=0.3224)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50 | Train Loss: 0.5029 | Val F1: 0.3118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50 | Train Loss: 0.4950 | Val F1: 0.3329\n",
            "‚úÖ Saved best model (F1=0.3329)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50 | Train Loss: 0.4783 | Val F1: 0.3834\n",
            "‚úÖ Saved best model (F1=0.3834)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50 | Train Loss: 0.4618 | Val F1: 0.3437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50 | Train Loss: 0.4428 | Val F1: 0.4088\n",
            "‚úÖ Saved best model (F1=0.4088)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50 | Train Loss: 0.4191 | Val F1: 0.3390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50 | Train Loss: 0.3926 | Val F1: 0.4215\n",
            "‚úÖ Saved best model (F1=0.4215)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50 | Train Loss: 0.3739 | Val F1: 0.4104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50 | Train Loss: 0.3518 | Val F1: 0.4225\n",
            "‚úÖ Saved best model (F1=0.4225)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50 | Train Loss: 0.3158 | Val F1: 0.4103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50 | Train Loss: 0.2907 | Val F1: 0.4503\n",
            "‚úÖ Saved best model (F1=0.4503)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50 | Train Loss: 0.2709 | Val F1: 0.4362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50 | Train Loss: 0.2433 | Val F1: 0.4549\n",
            "‚úÖ Saved best model (F1=0.4549)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50 | Train Loss: 0.2174 | Val F1: 0.4774\n",
            "‚úÖ Saved best model (F1=0.4774)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50 | Train Loss: 0.2010 | Val F1: 0.4617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50 | Train Loss: 0.1779 | Val F1: 0.4630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50 | Train Loss: 0.1649 | Val F1: 0.4652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50 | Train Loss: 0.1497 | Val F1: 0.4799\n",
            "‚úÖ Saved best model (F1=0.4799)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50 | Train Loss: 0.1285 | Val F1: 0.4685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50 | Train Loss: 0.1192 | Val F1: 0.4837\n",
            "‚úÖ Saved best model (F1=0.4837)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50 | Train Loss: 0.1092 | Val F1: 0.4651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50 | Train Loss: 0.0959 | Val F1: 0.4851\n",
            "‚úÖ Saved best model (F1=0.4851)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50 | Train Loss: 0.0883 | Val F1: 0.4639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50 | Train Loss: 0.0824 | Val F1: 0.4757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50 | Train Loss: 0.0737 | Val F1: 0.4668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50 | Train Loss: 0.0615 | Val F1: 0.4674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50 | Train Loss: 0.0620 | Val F1: 0.4811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50 | Train Loss: 0.0587 | Val F1: 0.4761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50 | Train Loss: 0.0508 | Val F1: 0.4736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50 | Train Loss: 0.0506 | Val F1: 0.4767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50 | Train Loss: 0.0431 | Val F1: 0.4783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50 | Train Loss: 0.0398 | Val F1: 0.4745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50 | Train Loss: 0.0404 | Val F1: 0.4737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50 | Train Loss: 0.0368 | Val F1: 0.4774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50 | Train Loss: 0.0347 | Val F1: 0.4741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50 | Train Loss: 0.0349 | Val F1: 0.4785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50 | Train Loss: 0.0321 | Val F1: 0.4796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50 | Train Loss: 0.0332 | Val F1: 0.4793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50 | Train Loss: 0.0315 | Val F1: 0.4808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50 | Train Loss: 0.0283 | Val F1: 0.4827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50 | Train Loss: 0.0292 | Val F1: 0.4825\n",
            "Training complete. Best F1: 0.4851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwwaUZpdgEDG",
        "outputId": "cfc74ad5-cd7a-4f3b-fcee-5229ad950178"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2JNEHiqnmeBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}